# EPIC-003: Performance Regression Test
# 
# æ€§èƒ½å›å½’æµ‹è¯•å·¥ä½œæµ
# åœ¨ PR æäº¤æ—¶è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼Œåœ¨åˆå¹¶åˆ° main æ—¶è¿è¡Œå®Œæ•´æµ‹è¯•

name: Performance Regression Test

on:
  pull_request:
    branches: [main, develop]
    paths:
      - 'apps/desktop/**'
      - 'packages/**'
      - 'tools/scripts/performance/**'
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode to run'
        required: false
        default: 'quick'
        type: choice
        options:
          - quick
          - full
          - memory

env:
  NODE_VERSION: '20'
  PNPM_VERSION: '10'

jobs:
  performance-test:
    name: Performance Test (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix:
        os: [windows-latest, ubuntu-latest, macos-latest]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: ${{ env.PNPM_VERSION }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'
      
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      
      - name: Build desktop application
        run: pnpm nx build desktop
        env:
          CI: true
      
      # æ ¹æ®è§¦å‘æ–¹å¼å†³å®šæµ‹è¯•æ¨¡å¼
      - name: Determine test mode
        id: mode
        shell: bash
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "mode=${{ inputs.test_mode }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" == "push" ]; then
            echo "mode=full" >> $GITHUB_OUTPUT
          else
            echo "mode=quick" >> $GITHUB_OUTPUT
          fi
      
      - name: Run performance benchmark
        id: benchmark
        run: |
          pnpm tsx tools/scripts/performance/run-benchmark.ts --${{ steps.mode.outputs.mode }}
        continue-on-error: true
      
      - name: Compare with baseline
        id: compare
        if: steps.benchmark.outcome == 'success'
        run: |
          pnpm tsx tools/scripts/performance/compare-baseline.ts
        continue-on-error: true
      
      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ matrix.os }}
          path: tools/scripts/performance/results/
          retention-days: 30
      
      - name: Post PR comment
        if: github.event_name == 'pull_request' && steps.compare.outputs.comment
        uses: actions/github-script@v7
        with:
          script: |
            const comment = `${{ steps.compare.outputs.comment }}`;
            
            // æŸ¥æ‰¾å·²æœ‰çš„æ€§èƒ½æŠ¥å‘Šè¯„è®º
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(c => 
              c.user?.type === 'Bot' && 
              c.body?.includes('Performance Comparison Report')
            );
            
            if (botComment) {
              // æ›´æ–°å·²æœ‰è¯„è®º
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              // åˆ›å»ºæ–°è¯„è®º
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
      
      - name: Check regression status
        if: steps.compare.outputs.regression == 'true'
        run: |
          echo "::error::Performance regression detected!"
          exit 1

  # åœ¨æ‰€æœ‰å¹³å°æµ‹è¯•å®Œæˆåæ±‡æ€»ç»“æœ
  aggregate-results:
    name: Aggregate Results
    needs: performance-test
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Summarize results
        run: |
          echo "## ğŸ“Š Performance Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          for dir in artifacts/benchmark-results-*/; do
            os=$(basename "$dir" | sed 's/benchmark-results-//')
            echo "### $os" >> $GITHUB_STEP_SUMMARY
            
            if [ -f "$dir/latest.json" ]; then
              cat "$dir/latest.json" | jq -r '
                "| Metric | Value | Target | Status |",
                "|--------|-------|--------|--------|",
                "| Cold Startup | \(.metrics.coldStartup | floor)ms | < 3000ms | \(if .metrics.coldStartup < 3000 then "âœ…" else "âŒ" end) |",
                "| Memory (Idle) | \(.metrics.memoryAtIdle | floor)MB | < 300MB | \(if .metrics.memoryAtIdle < 300 then "âœ…" else "âŒ" end) |",
                "| IPC Latency | \(.metrics.ipcAvgLatency | . * 10 | floor / 10)ms | < 30ms | \(if .metrics.ipcAvgLatency < 30 then "âœ…" else "âŒ" end) |"
              ' >> $GITHUB_STEP_SUMMARY
            else
              echo "No results found" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "" >> $GITHUB_STEP_SUMMARY
          done

  # æ¯æ—¥å®Œæ•´æ€§èƒ½æµ‹è¯• (å¯é€‰)
  scheduled-full-test:
    name: Scheduled Full Performance Test
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    
    steps:
      - name: Trigger full test
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'performance.yml',
              ref: 'main',
              inputs: {
                test_mode: 'full'
              }
            });
